{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unstructured\n",
    "!pip install unstructured[docx]\n",
    "!pip install -q cassio datasets langchain tiktoken\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Directory Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Github\\langchain\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('./content', show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docs)):\n",
    "    print(docs[i].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown loader\n",
    "# from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# loader = UnstructuredMarkdownLoader('AIconsultingdevelopmentservices.md',mode=\"elements\" , show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = loader.load()\n",
    "# for i in range(len(data)):\n",
    "#     print(f\"{i}\\t\" ,data[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('./pdfs', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# d = loader.load_and_split()\n",
    "# d[5].page_content\n",
    "# for i in range(len(d)):\n",
    "#     print(d[i].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open folder\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "doc_dict = dict()\n",
    "for file in os.listdir(\"./pdfs\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(f\"./pdfs/{file}\")\n",
    "        x = loader.load_and_split()\n",
    "        doc_dict[file] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in doc_dict.keys():\n",
    "    # print(i, \"\\t\", len(doc_dict[i]))\n",
    "    sum += len(doc_dict[i])\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = list()\n",
    "for i in doc_dict.values():\n",
    "    for j in i:\n",
    "        doc_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages : 116\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of pages :\" , len(doc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aboutus.pdf_0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{doc_list[0].metadata['source'].split('/')[-1]}_{doc_list[0].metadata['page']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitter for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pages using pyPDF2\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# loader = PyPDFLoader('About us.pdf')\n",
    "# docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(len(doc_list)):\n",
    "    print(doc_list[_].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict[docs[0].metadata['source']] = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 246.68it/s]\n"
     ]
    }
   ],
   "source": [
    "chunklist = []\n",
    "\n",
    "for i in tqdm(range(len(docs))):\n",
    "    texts = text_splitter.split_text(docs[i].page_content)\n",
    "    chunklist.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunklist[0][1].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitter for PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunklist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from datasets import load_dataset\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"clientId\": \"vojbKbGDdCRrSKhkRvABraBr\",\n",
    "  \"secret\": \"qZ23HXAoyrqzNTm41BJyl5Y0ujrO65lFXcEJ8GOolu_jUa4B_lR+LAj,2_Fbiw+67frXW-6E+YHk1oPb63Y7MZ+GZ008C7gToJhS2w9I1i1Q-qspT97kbfS84o6pLs.R\",\n",
    "  \"token\": \"AstraCS:vojbKbGDdCRrSKhkRvABraBr:863a31ec15ff213b2e3a152f1776299cb4dfde364eec30eebf783091e2fe0bf8\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing_extensions import Concatenate\n",
    "# raw_text = ''\n",
    "\n",
    "# for i in range(len(docs)):\n",
    "#     raw_text += docs[i].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"postgresql+psycopg2://harrisonchase@localhost:5432/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import AstraDB,PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"PGVECTOR_DRIVER\", \"psycopg2\"),\n",
    "    host=os.environ.get(\"PGVECTOR_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"PGVECTOR_PORT\", \"5433\")),\n",
    "    database=os.environ.get(\"PGVECTOR_DATABASE\", \"postgres\"),\n",
    "    user=os.environ.get(\"PGVECTOR_USER\", \"postgres\"),\n",
    "    password=os.environ.get(\"PGVECTOR_PASSWORD\", \"admin\"),\n",
    ")\n",
    "COLLECTION_NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# def create_faiss_index(embeddings, dimension):\n",
    "#     index = faiss.IndexFlatL2(dimension)  # For cosine similarity with L2 distance\n",
    "#     index.add(embeddings)\n",
    "#     return index\n",
    "\n",
    "# embeddings = embedding.embed_query(\"hello\")\n",
    "# create_faiss_index(embeddings, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "model = HuggingFaceEmbeddings()\n",
    "COLLECTION_NAME = \"test\"\n",
    "db = PGVector.from_documents(\n",
    "    embedding=model,\n",
    "    documents=doc_list,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.embed_query('AWS sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Collection not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:637\u001b[0m, in \u001b[0;36mPGVector.similarity_search_by_vector\u001b[1;34m(self, embedding, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_by_vector\u001b[39m(\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    622\u001b[0m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    626\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to embedding vector.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs(docs_and_scores)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:493\u001b[0m, in \u001b[0;36mPGVector.similarity_search_with_score_by_vector\u001b[1;34m(self, embedding, k, filter)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score_by_vector\u001b[39m(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    489\u001b[0m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m    490\u001b[0m     k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28mfilter\u001b[39m: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m--> 493\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_to_docs_and_scores(results)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:581\u001b[0m, in \u001b[0;36mPGVector.__query_collection\u001b[1;34m(self, embedding, k, filter)\u001b[0m\n\u001b[0;32m    579\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collection(session)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m collection:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    583\u001b[0m filter_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEmbeddingStore\u001b[38;5;241m.\u001b[39mcollection_id \u001b[38;5;241m==\u001b[39m collection\u001b[38;5;241m.\u001b[39muuid\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Collection not found"
     ]
    }
   ],
   "source": [
    "db.similarity_search_by_vector(vector, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "DB_NAME = 'postgres'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'admin'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5433'\n",
    "def execute_query(user_query, model):\n",
    "    query_embedding = model.embed_query(user_query)\n",
    "    conn = psycopg2.connect(database=DB_NAME,\n",
    "                                user=DB_USER,\n",
    "                                password=DB_PASSWORD,\n",
    "                                host=DB_HOST,\n",
    "                                port= DB_PORT)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        \n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT public.cosine_similarity(embedding, %(vector)s::vector) AS similarity\n",
    "            FROM langchain_pg_embedding;\n",
    "        \"\"\", {'vector': query_embedding})\n",
    "\n",
    "        results = cursor.fetchall()\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(model.embed_query('AWS sagemaker'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(\"hello\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(model.embed_query(\"aws cloud sagemaker azure google cloud platform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.pgvector.PGVector at 0x1d6f3372830>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db.add_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Github\\langchain\\langchain\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# cassio.init(database_id=ASTRA_DB_ID, token=ASTRA_DB_TOKEN)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hugging face embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.embed_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_ENDPOINT = \"https://7c0f8dc7-64fc-4933-8e6a-54012dd88d6f-centralindia.apps.astra.datastax.com\"\n",
    "ASTRA_DB_TOKEN = \"AstraCS:aXvdbOYgcdTfbqbzLtUraZmr:3d5c04059d72e98b77260d4f74956bbb05c619e416fe02a3a88f938ca56b722b\"\n",
    "vstore = AstraDB(\n",
    "    embedding=embedding,\n",
    "    collection_name=\"test\",\n",
    "    token=ASTRA_DB_TOKEN,\n",
    "    api_endpoint=ASTRA_DB_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserted 116 documents.\n"
     ]
    }
   ],
   "source": [
    "inserted_ids = vstore.add_documents(doc_list)\n",
    "print(f\"\\nInserted {len(inserted_ids)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding.embed_query('Please tell me about your services')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_ID = \"7c0f8dc7-64fc-4933-8e6a-54012dd88d6f\"\n",
    "# import cassio library\n",
    "import cassio\n",
    "\n",
    "cassio.init(database_id=ASTRA_DB_ID, token=ASTRA_DB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequest",
     "evalue": "Error from server: code=2200 [Invalid query] message=\"Undefined column name vector in table \"default_keyspace\".test\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequest\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcassandra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cassandra\n\u001b[1;32m----> 2\u001b[0m astra_vector_cass \u001b[38;5;241m=\u001b[39m \u001b[43mCassandra\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\langchain_community\\vectorstores\\cassandra.py:93\u001b[0m, in \u001b[0;36mCassandra.__init__\u001b[1;34m(self, embedding, session, keyspace, table_name, ttl_seconds)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable \u001b[38;5;241m=\u001b[39m \u001b[43mMetadataVectorCassandraTable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeyspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_embedding_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_indexing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_key_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEXT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\mixins.py:720\u001b[0m, in \u001b[0;36mTypeNormalizerMixin.__init__\u001b[1;34m(self, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     new_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m--> 720\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39mpargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\mixins.py:195\u001b[0m, in \u001b[0;36mMetadataMixin.__init__\u001b[1;34m(self, metadata_indexing, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39mpargs: Any,\n\u001b[0;32m    189\u001b[0m     metadata_indexing: Union[Tuple[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_indexing_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_metadata_indexing_policy(\n\u001b[0;32m    193\u001b[0m         metadata_indexing\n\u001b[0;32m    194\u001b[0m     )\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39mpargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\mixins.py:490\u001b[0m, in \u001b[0;36mVectorMixin.__init__\u001b[1;34m(self, vector_dimension, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mpargs: Any, vector_dimension: \u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_dimension \u001b[38;5;241m=\u001b[39m vector_dimension\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39mpargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\base_table.py:44\u001b[0m, in \u001b[0;36mBaseTable.__init__\u001b[1;34m(self, table, session, keyspace, ttl_seconds, row_id_type, skip_provisioning)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_provisioning \u001b[38;5;241m=\u001b[39m skip_provisioning\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepared_statements: Dict[\u001b[38;5;28mstr\u001b[39m, PreparedStatement] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\mixins.py:246\u001b[0m, in \u001b[0;36mMetadataMixin.db_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdb_setup\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# Currently: an 'entries' index on the metadata_s column\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     entries_index_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_s\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\mixins.py:506\u001b[0m, in \u001b[0;36mVectorMixin.db_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m index_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m create_index_cql \u001b[38;5;241m=\u001b[39m CREATE_INDEX_CQL_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    503\u001b[0m     index_name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[0;32m    504\u001b[0m     index_column\u001b[38;5;241m=\u001b[39mindex_column,\n\u001b[0;32m    505\u001b[0m )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_cql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_index_cql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCQLOpType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCHEMA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassio\\table\\base_table.py:327\u001b[0m, in \u001b[0;36mBaseTable.execute_cql\u001b[1;34m(self, cql_semitemplate, op_type, args)\u001b[0m\n\u001b[0;32m    325\u001b[0m     statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obtain_prepared_statement(final_cql)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Iterable[RowType], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassandra\\cluster.py:2677\u001b[0m, in \u001b[0;36mcassandra.cluster.Session.execute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mg:\\Github\\langchain\\langchain\\lib\\site-packages\\cassandra\\cluster.py:4956\u001b[0m, in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mInvalidRequest\u001b[0m: Error from server: code=2200 [Invalid query] message=\"Undefined column name vector in table \"default_keyspace\".test\""
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "astra_vector_cass = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"test\", \n",
    "    keyspace=None,\n",
    "    session=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"Enter your query(or type quit to stop): \")\n",
    "    else :\n",
    "        query_text = input(\"What is your next query (or type quit to stop) : \")\n",
    "    \n",
    "    if query_text.lower() == 'quit':\n",
    "        break\n",
    "    \n",
    "    if query_text == '':\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(f\"{query_text}\\nSearching for similar documents...\")\n",
    "    answer = vstore."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
